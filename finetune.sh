OMP_NUM_THREADS=1 python -m torch.distributed.launch --nproc_per_node=8 --master_port='30515' main_finetune.py \
    --accum_iter 4 \
    --batch_size 64 \
    --model vit_large_patch16 --cls_token\
    --finetune 'temp_dir-large-TCR-1e-2-lamda-3/checkpoint-199.pth'\
    --epochs 100 \
    --blr 5e-4 --layer_decay 0.65 \
    --weight_decay 0.05 --drop_path 0.1 --mixup 0.8 --cutmix 1.0 --reprob 0.25 \
    --log_dir temp_dir-large-TCR-1e-2-lamda-3\
    --output_dir output_dir-large-finetune-TCR-1e-2-lamda-3\
    --dist_eval --data_path ../imagenet
